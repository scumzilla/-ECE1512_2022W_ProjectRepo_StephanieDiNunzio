{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WYMfvCNPwpm"
      },
      "source": [
        "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vA8ppgB2P0aJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Stephanie\\anaconda3\\envs\\ece1512\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Union\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "BATCH_SIZE = 256\n",
        "NUM_EPOCHS = 12\n",
        "NUM_CLASSES = 2 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2EFLQROP2R7"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Name</th>\n",
              "      <th>Majority Vote Label</th>\n",
              "      <th>Partition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MHIST_aaa.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MHIST_aab.png</td>\n",
              "      <td>HP</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MHIST_aac.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MHIST_aae.png</td>\n",
              "      <td>HP</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MHIST_aaf.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3147</th>\n",
              "      <td>MHIST_cpn.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3148</th>\n",
              "      <td>MHIST_cfc.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3149</th>\n",
              "      <td>MHIST_cgp.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3150</th>\n",
              "      <td>MHIST_dlf.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3151</th>\n",
              "      <td>MHIST_cks.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3152 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Image Name Majority Vote Label Partition\n",
              "0     MHIST_aaa.png                 SSA     train\n",
              "1     MHIST_aab.png                  HP     train\n",
              "2     MHIST_aac.png                 SSA     train\n",
              "3     MHIST_aae.png                  HP     train\n",
              "4     MHIST_aaf.png                 SSA     train\n",
              "...             ...                 ...       ...\n",
              "3147  MHIST_cpn.png                 SSA     train\n",
              "3148  MHIST_cfc.png                 SSA      test\n",
              "3149  MHIST_cgp.png                 SSA      test\n",
              "3150  MHIST_dlf.png                 SSA     train\n",
              "3151  MHIST_cks.png                 SSA     train\n",
              "\n",
              "[3152 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load train and test splits.\n",
        "anno_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\annotations.csv' #you should change to your directory\n",
        "df = pd.read_csv(anno_dir)\n",
        "df = df[['Image Name','Majority Vote Label','Partition']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "hp_test_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\HP_test'\n",
        "hp_train_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\HP_train'\n",
        "ssa_test_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\SSA_test'\n",
        "ssa_train_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\SSA_train'\n",
        "\n",
        "img_root_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images\\images'\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    img_dir = img_root_dir + '\\\\' + row['Image Name']\n",
        "    if row['Majority Vote Label'] == 'SSA':\n",
        "        if row['Partition'] == 'train':\n",
        "            new_dir = ssa_train_dir + '\\\\' + row['Image Name']\n",
        "            shutil.copyfile(img_dir,new_dir)\n",
        "        else:\n",
        "            new_dir = ssa_test_dir + '\\\\' + row['Image Name']\n",
        "            shutil.copyfile(img_dir,new_dir)\n",
        "    else:\n",
        "        if row['Partition'] == 'train':\n",
        "            new_dir = hp_train_dir + '\\\\' + row['Image Name']\n",
        "            shutil.copyfile(img_dir,new_dir)\n",
        "        else:\n",
        "            new_dir = hp_test_dir + '\\\\' + row['Image Name']\n",
        "            shutil.copyfile(img_dir,new_dir)\n",
        "    #break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ynByMG_UP4A4"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\test'\n",
        "train_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\train'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
        "shear_range=0.1,\n",
        "rotation_range=15,\n",
        "horizontal_flip=True,\n",
        "vertical_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "class_mode='categorical',\n",
        "interpolation='bilinear',\n",
        "target_size=(224, 224),\n",
        "batch_size=32,\n",
        "shuffle=True)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "class_mode='categorical',\n",
        "interpolation='bilinear',\n",
        "target_size=(224, 224),\n",
        "batch_size=32,\n",
        "shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAZwfvW5P63q"
      },
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zINgDkA7P7BP"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "\n",
        "# Build CNN teacher.\n",
        "cnn_model = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for stpe 2\n",
        "from tensorflow.keras import layers\n",
        " \n",
        "cnn_model.add(layers.Conv2D(32,3,strides=1,padding='same',activation='relu',input_shape=(28,28,1)))\n",
        "cnn_model.add(layers.MaxPool2D(pool_size=(2,2),strides=1))\n",
        "cnn_model.add(layers.Conv2D(64,3,strides=1,padding='same',activation='relu'))\n",
        "cnn_model.add(layers.MaxPool2D(pool_size=(2,2),strides=2))\n",
        "cnn_model.add(layers.Flatten())\n",
        "cnn_model.add(layers.Dropout(0.5))\n",
        "cnn_model.add(layers.Dense(128,activation='relu'))\n",
        "cnn_model.add(layers.Dropout(0.5))\n",
        "cnn_model.add(layers.Dense(128,activation='relu'))\n",
        "cnn_model.add(layers.Dropout(0.5))\n",
        "cnn_model.add(layers.Dense(NUM_CLASSES))\n",
        "##\n",
        "\n",
        "#cnn_model.summary()\n",
        "\n",
        "\n",
        "# Build fully connected student.\n",
        "fc_model = tf.keras.Sequential()\n",
        "\n",
        "# your code start from here for step 2\n",
        "\n",
        "fc_model.add(layers.Flatten())\n",
        "fc_model.add(layers.Dense(784,activation='relu'))\n",
        "fc_model.add(layers.Dense(784,activation='relu'))\n",
        "fc_model.add(layers.Dense(NUM_CLASSES))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JWGucyrQGav"
      },
      "source": [
        "# Teacher loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DhzBP6ZLQJ57"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "@tf.function\n",
        "def compute_teacher_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  class_logits = cnn_model(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for classes.\n",
        "\n",
        "  # your code start from here for step 3\n",
        " \n",
        "  loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  \n",
        "  cross_entropy_loss_value = loss(labels,class_logits)\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS8xkuH0QbOS"
      },
      "source": [
        "# Student loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lDKia4gPQMIr"
      },
      "outputs": [],
      "source": [
        "#@test {\"output\": \"ignore\"}\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 4. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = tf.nn.softmax(teacher_logits)\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_class_logits = fc_model(images, training=True)\n",
        "\n",
        "  # Compute class distillation loss between student class logits and\n",
        "  # softened teacher class targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_class_logits = cnn_model(images, training=False)\n",
        "  distillation_loss_value = distillation_loss(teacher_class_logits, student_class_logits, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  loss = keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "  \n",
        "  cross_entropy_loss_value = loss(labels,student_class_logits).numpy()\n",
        "\n",
        "  return ALPHA*cross_entropy_loss_value + (1-ALPHA)*distillation_loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJ1uyvurQ3w4"
      },
      "source": [
        "# Train and evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EtoLbp8uQ4Vl"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.reduce_sum(\n",
        "      tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),\n",
        "              tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)\n",
        "\n",
        "\n",
        "def train_and_evaluate(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "  for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    for images, labels in mnist_train:\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "        loss_value = compute_loss_fn(images, labels)\n",
        "        #tape.watch(loss_value)\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = builder.info.splits['test'].num_examples\n",
        "    for images, labels in mnist_test:\n",
        "      # your code start from here for step 4\n",
        "      num_correct += compute_num_correct(model, images, labels)[0]\n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "\n",
        "  return num_correct / num_total\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQL1lJdaRPT1"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Class_accuracy: 97.54%\n",
            "Epoch 2: Class_accuracy: 98.07%\n",
            "Epoch 3: Class_accuracy: 98.70%\n",
            "Epoch 4: Class_accuracy: 98.71%\n",
            "Epoch 5: Class_accuracy: 98.92%\n",
            "Epoch 6: Class_accuracy: 98.94%\n",
            "Epoch 7: Class_accuracy: 99.01%\n",
            "Epoch 8: Class_accuracy: 99.11%\n",
            "Epoch 9: Class_accuracy: 99.07%\n",
            "Epoch 10: Class_accuracy: 99.07%\n",
            "Epoch 11: Class_accuracy: 99.11%\n",
            "Epoch 12: Class_accuracy: 99.19%\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.9919>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_and_evaluate(cnn_model, compute_teacher_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Class_accuracy: 96.34%\n",
            "Epoch 2: Class_accuracy: 97.57%\n",
            "Epoch 3: Class_accuracy: 97.64%\n",
            "Epoch 4: Class_accuracy: 97.96%\n",
            "Epoch 5: Class_accuracy: 98.03%\n",
            "Epoch 6: Class_accuracy: 98.17%\n",
            "Epoch 7: Class_accuracy: 98.29%\n",
            "Epoch 8: Class_accuracy: 98.16%\n",
            "Epoch 9: Class_accuracy: 98.21%\n",
            "Epoch 10: Class_accuracy: 98.27%\n",
            "Epoch 11: Class_accuracy: 98.42%\n",
            "Epoch 12: Class_accuracy: 98.57%\n"
          ]
        }
      ],
      "source": [
        "##RESET MODEL\n",
        "\n",
        "# Build fully connected student.\n",
        "fc_model = tf.keras.Sequential()\n",
        "\n",
        "fc_model.add(layers.Flatten())\n",
        "fc_model.add(layers.Dense(784,activation='relu'))\n",
        "fc_model.add(layers.Dense(784,activation='relu'))\n",
        "fc_model.add(layers.Dense(NUM_CLASSES))\n",
        "\n",
        "\n",
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 2.5 #temperature hyperparameter\n",
        "\n",
        "# your code start from here for step 5 \n",
        "\n",
        "accuracy = train_and_evaluate(fc_model, compute_student_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.9857\n"
          ]
        }
      ],
      "source": [
        "print(accuracy.numpy())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Task1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
