{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WYMfvCNPwpm"
      },
      "source": [
        "# Project B: Knowledge Distillation for Building Lightweight Deep Learning Models in Visual Classification Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vA8ppgB2P0aJ"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v2 as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from typing import Union\n",
        "\n",
        "tf.enable_v2_behavior()\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2EFLQROP2R7"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Image Name</th>\n",
              "      <th>Majority Vote Label</th>\n",
              "      <th>Partition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>MHIST_aaa.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MHIST_aab.png</td>\n",
              "      <td>HP</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MHIST_aac.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MHIST_aae.png</td>\n",
              "      <td>HP</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>MHIST_aaf.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3147</th>\n",
              "      <td>MHIST_cpn.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3148</th>\n",
              "      <td>MHIST_cfc.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3149</th>\n",
              "      <td>MHIST_cgp.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3150</th>\n",
              "      <td>MHIST_dlf.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3151</th>\n",
              "      <td>MHIST_cks.png</td>\n",
              "      <td>SSA</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3152 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         Image Name Majority Vote Label Partition\n",
              "0     MHIST_aaa.png                 SSA     train\n",
              "1     MHIST_aab.png                  HP     train\n",
              "2     MHIST_aac.png                 SSA     train\n",
              "3     MHIST_aae.png                  HP     train\n",
              "4     MHIST_aaf.png                 SSA     train\n",
              "...             ...                 ...       ...\n",
              "3147  MHIST_cpn.png                 SSA     train\n",
              "3148  MHIST_cfc.png                 SSA      test\n",
              "3149  MHIST_cgp.png                 SSA      test\n",
              "3150  MHIST_dlf.png                 SSA     train\n",
              "3151  MHIST_cks.png                 SSA     train\n",
              "\n",
              "[3152 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load train and test splits.\n",
        "anno_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\annotations.csv' #you should change to your directory\n",
        "df = pd.read_csv(anno_dir)\n",
        "df = df[['Image Name','Majority Vote Label','Partition']]\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "hp_test_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\test\\HP_test'\n",
        "hp_train_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\train\\HP_train'\n",
        "ssa_test_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\test\\SSA_test'\n",
        "ssa_train_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\train\\SSA_train'\n",
        "\n",
        "img_root_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images\\images'\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    img_dir = img_root_dir + '\\\\' + row['Image Name']\n",
        "    if row['Majority Vote Label'] == 'SSA':\n",
        "        if row['Partition'] == 'train':\n",
        "            new_dir = ssa_train_dir + '\\\\' + row['Image Name']\n",
        "            shutil.copyfile(img_dir,new_dir)\n",
        "        else:\n",
        "            new_dir = ssa_test_dir + '\\\\' + row['Image Name']\n",
        "            shutil.copyfile(img_dir,new_dir)\n",
        "    else:\n",
        "        if row['Partition'] == 'train':\n",
        "            new_dir = hp_train_dir + '\\\\' + row['Image Name']\n",
        "            shutil.copyfile(img_dir,new_dir)\n",
        "        else:\n",
        "            new_dir = hp_test_dir + '\\\\' + row['Image Name']\n",
        "            shutil.copyfile(img_dir,new_dir)\n",
        "    #break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ynByMG_UP4A4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2175 images belonging to 2 classes.\n",
            "Found 977 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "test_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\test'\n",
        "train_dir = r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\mhist_dataset\\images_sorted\\train'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
        "shear_range=0.1,\n",
        "rotation_range=15,\n",
        "zoom_range=0.2, # zoom\n",
        "horizontal_flip=True,\n",
        "vertical_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "class_mode='binary',\n",
        "interpolation='bilinear',\n",
        "target_size=(224, 224),\n",
        "batch_size=32,\n",
        "shuffle=True,)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(test_dir,\n",
        "class_mode='binary',\n",
        "interpolation='bilinear',\n",
        "target_size=(224, 224),\n",
        "batch_size=32,\n",
        "shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAZwfvW5P63q"
      },
      "source": [
        "# Model creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "resnet50v2 (Functional)      (None, None, None, 2048)  23564800  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 2049      \n",
            "=================================================================\n",
            "Total params: 23,566,849\n",
            "Trainable params: 2,049\n",
            "Non-trainable params: 23,564,800\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "resnet = tf.keras.applications.resnet_v2.ResNet50V2(weights='imagenet', include_top=False)\n",
        "resnet.trainable = False\n",
        "\n",
        "inputs = keras.Input(shape=(224,224,3))\n",
        "x = resnet(inputs, training=False)\n",
        "x= layers.GlobalAveragePooling2D()(x)\n",
        "outputs = layers.Dense(1)(x)\n",
        "\n",
        "\n",
        "teacher_model = keras.Model(inputs, outputs)\n",
        "teacher_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQL1lJdaRPT1"
      },
      "source": [
        "# Training models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "LEARNING_RATE = 0.001\n",
        "teacher_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "67/67 [==============================] - 18s 239ms/step - loss: 0.5261 - accuracy: 0.7345 - val_loss: 0.5046 - val_accuracy: 0.7146\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 15s 227ms/step - loss: 0.4266 - accuracy: 0.7928 - val_loss: 0.4582 - val_accuracy: 0.7542\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 15s 227ms/step - loss: 0.4081 - accuracy: 0.8021 - val_loss: 0.4528 - val_accuracy: 0.7604\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 15s 226ms/step - loss: 0.3869 - accuracy: 0.8101 - val_loss: 0.4441 - val_accuracy: 0.7729\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 15s 227ms/step - loss: 0.3920 - accuracy: 0.8115 - val_loss: 0.4482 - val_accuracy: 0.7615\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 15s 229ms/step - loss: 0.3798 - accuracy: 0.8171 - val_loss: 0.4536 - val_accuracy: 0.7615\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 15s 229ms/step - loss: 0.3774 - accuracy: 0.8245 - val_loss: 0.4341 - val_accuracy: 0.7833\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 15s 226ms/step - loss: 0.3661 - accuracy: 0.8362 - val_loss: 0.4357 - val_accuracy: 0.7760\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 15s 226ms/step - loss: 0.3755 - accuracy: 0.8157 - val_loss: 0.4263 - val_accuracy: 0.8021\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 15s 225ms/step - loss: 0.3646 - accuracy: 0.8320 - val_loss: 0.4464 - val_accuracy: 0.7698\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2271868a1c0>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "teacher_model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
        "                    epochs=10,                  \n",
        "                    shuffle = True,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=test_generator.n // BATCH_SIZE,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {},
      "outputs": [],
      "source": [
        "teacher_model.save(r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\models\\mhist_model_init.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "resnet.trainable = True\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "teacher_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "67/67 [==============================] - 22s 258ms/step - loss: 0.6173 - accuracy: 0.7070 - val_loss: 0.5658 - val_accuracy: 0.6427\n",
            "Epoch 2/25\n",
            "67/67 [==============================] - 16s 231ms/step - loss: 0.5466 - accuracy: 0.7158 - val_loss: 0.5588 - val_accuracy: 0.6427\n",
            "Epoch 3/25\n",
            "67/67 [==============================] - 16s 236ms/step - loss: 0.4883 - accuracy: 0.7280 - val_loss: 0.5106 - val_accuracy: 0.7042\n",
            "Epoch 4/25\n",
            "67/67 [==============================] - 16s 231ms/step - loss: 0.4668 - accuracy: 0.7625 - val_loss: 0.4893 - val_accuracy: 0.7625\n",
            "Epoch 5/25\n",
            "67/67 [==============================] - 16s 230ms/step - loss: 0.4316 - accuracy: 0.7797 - val_loss: 0.4381 - val_accuracy: 0.7896\n",
            "Epoch 6/25\n",
            "67/67 [==============================] - 15s 229ms/step - loss: 0.4189 - accuracy: 0.7839 - val_loss: 0.4183 - val_accuracy: 0.7833\n",
            "Epoch 7/25\n",
            "67/67 [==============================] - 16s 236ms/step - loss: 0.3710 - accuracy: 0.8255 - val_loss: 0.3807 - val_accuracy: 0.7958\n",
            "Epoch 8/25\n",
            "67/67 [==============================] - 16s 233ms/step - loss: 0.3627 - accuracy: 0.8255 - val_loss: 0.4426 - val_accuracy: 0.7688\n",
            "Epoch 9/25\n",
            "67/67 [==============================] - 16s 236ms/step - loss: 0.3713 - accuracy: 0.8213 - val_loss: 0.4923 - val_accuracy: 0.7479\n",
            "Epoch 10/25\n",
            "67/67 [==============================] - 15s 230ms/step - loss: 0.3094 - accuracy: 0.8628 - val_loss: 0.3562 - val_accuracy: 0.8177\n",
            "Epoch 11/25\n",
            "67/67 [==============================] - 16s 234ms/step - loss: 0.2968 - accuracy: 0.8614 - val_loss: 0.4033 - val_accuracy: 0.8250\n",
            "Epoch 12/25\n",
            "67/67 [==============================] - 16s 232ms/step - loss: 0.3016 - accuracy: 0.8549 - val_loss: 0.4071 - val_accuracy: 0.7865\n",
            "Epoch 13/25\n",
            "67/67 [==============================] - 16s 236ms/step - loss: 0.2977 - accuracy: 0.8707 - val_loss: 0.3936 - val_accuracy: 0.8344\n",
            "Epoch 14/25\n",
            "67/67 [==============================] - 15s 227ms/step - loss: 0.2700 - accuracy: 0.8843 - val_loss: 0.3416 - val_accuracy: 0.8156\n",
            "Epoch 15/25\n",
            "67/67 [==============================] - 16s 236ms/step - loss: 0.2695 - accuracy: 0.8773 - val_loss: 0.3803 - val_accuracy: 0.8031\n",
            "Epoch 16/25\n",
            "67/67 [==============================] - 16s 232ms/step - loss: 0.2558 - accuracy: 0.8824 - val_loss: 0.3510 - val_accuracy: 0.8385\n",
            "Epoch 17/25\n",
            "67/67 [==============================] - 16s 232ms/step - loss: 0.2555 - accuracy: 0.8847 - val_loss: 0.4304 - val_accuracy: 0.7896\n",
            "Epoch 18/25\n",
            "67/67 [==============================] - 15s 226ms/step - loss: 0.2533 - accuracy: 0.8889 - val_loss: 0.3549 - val_accuracy: 0.8198\n",
            "Epoch 19/25\n",
            "67/67 [==============================] - 15s 230ms/step - loss: 0.2513 - accuracy: 0.8950 - val_loss: 0.3204 - val_accuracy: 0.8677\n",
            "Epoch 20/25\n",
            "67/67 [==============================] - 16s 230ms/step - loss: 0.2518 - accuracy: 0.8927 - val_loss: 0.3371 - val_accuracy: 0.8427\n",
            "Epoch 21/25\n",
            "67/67 [==============================] - 16s 235ms/step - loss: 0.2133 - accuracy: 0.9085 - val_loss: 0.3154 - val_accuracy: 0.8719\n",
            "Epoch 22/25\n",
            "67/67 [==============================] - 15s 226ms/step - loss: 0.2069 - accuracy: 0.9071 - val_loss: 0.3301 - val_accuracy: 0.8562\n",
            "Epoch 23/25\n",
            "67/67 [==============================] - 16s 232ms/step - loss: 0.2240 - accuracy: 0.9006 - val_loss: 0.3572 - val_accuracy: 0.8510\n",
            "Epoch 24/25\n",
            "67/67 [==============================] - 16s 237ms/step - loss: 0.1984 - accuracy: 0.9146 - val_loss: 0.4618 - val_accuracy: 0.8010\n",
            "Epoch 25/25\n",
            "67/67 [==============================] - 16s 239ms/step - loss: 0.2026 - accuracy: 0.9127 - val_loss: 0.3930 - val_accuracy: 0.8406\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x22726545070>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "teacher_model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
        "                    epochs=25,                  \n",
        "                    shuffle = True,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=test_generator.n // BATCH_SIZE,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Stephanie\\anaconda3\\envs\\ece1512\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  warnings.warn('Custom mask layers require a config and must override '\n"
          ]
        }
      ],
      "source": [
        "teacher_model.save(r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\models\\mhist_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Stephanie\\anaconda3\\envs\\ece1512\\lib\\site-packages\\keras\\engine\\training.py:2006: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test loss, test acc: [0.3987638056278229, 0.838280439376831]\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = teacher_model.evaluate_generator(generator=test_generator)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Stephanie\\anaconda3\\envs\\ece1512\\lib\\site-packages\\keras\\engine\\training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0.835655</td>\n",
              "      <td>0.972447</td>\n",
              "      <td>0.898876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>0.934363</td>\n",
              "      <td>0.672222</td>\n",
              "      <td>0.781906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.861822</td>\n",
              "      <td>0.861822</td>\n",
              "      <td>0.861822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.885009</td>\n",
              "      <td>0.822335</td>\n",
              "      <td>0.840391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.872026</td>\n",
              "      <td>0.861822</td>\n",
              "      <td>0.855776</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision    recall  f1-score\n",
              "0.0            0.835655  0.972447  0.898876\n",
              "1.0            0.934363  0.672222  0.781906\n",
              "accuracy       0.861822  0.861822  0.861822\n",
              "macro avg      0.885009  0.822335  0.840391\n",
              "weighted avg   0.872026  0.861822  0.855776"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "test_data = []\n",
        "test_labels = []\n",
        "\n",
        "for j in range(len(test_generator)):\n",
        "    test_labels += test_generator[j][1].tolist()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = teacher_model.predict_generator(test_generator)\n",
        "pred_classes = []\n",
        "\n",
        "\n",
        "\n",
        "for i in pred:\n",
        "    if i[0] < 0:\n",
        "        pred_classes.append(0)\n",
        "    else:\n",
        "        pred_classes.append(1)\n",
        "\n",
        "report = classification_report(test_labels,pred_classes,output_dict=True)\n",
        "df = pd.DataFrame(report).transpose()\n",
        "df.pop('support')\n",
        "df = pd.concat([df[0:8] , df[10:]])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_10 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Build student. NO KD\n",
        "\n",
        "mobilenet = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), include_top=False, weights='imagenet')\n",
        "mobilenet.trainable = False\n",
        "\n",
        "inputs2 = keras.Input(shape=(224,224,3))\n",
        "y = mobilenet(inputs2, training=False)\n",
        "y= layers.GlobalAveragePooling2D()(y)\n",
        "outputs2 = layers.Dense(1)(y)\n",
        "\n",
        "student_model = keras.Model(inputs2, outputs2)\n",
        "student_model.summary()\n",
        "\n",
        "\n",
        "# \n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "student_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "67/67 [==============================] - 18s 237ms/step - loss: 0.5764 - accuracy: 0.7224 - val_loss: 0.5204 - val_accuracy: 0.6958\n",
            "Epoch 2/10\n",
            "67/67 [==============================] - 15s 231ms/step - loss: 0.4575 - accuracy: 0.7713 - val_loss: 0.5021 - val_accuracy: 0.7115\n",
            "Epoch 3/10\n",
            "67/67 [==============================] - 15s 227ms/step - loss: 0.4241 - accuracy: 0.7886 - val_loss: 0.4954 - val_accuracy: 0.7250\n",
            "Epoch 4/10\n",
            "67/67 [==============================] - 15s 228ms/step - loss: 0.4121 - accuracy: 0.8059 - val_loss: 0.4721 - val_accuracy: 0.7448\n",
            "Epoch 5/10\n",
            "67/67 [==============================] - 15s 228ms/step - loss: 0.3966 - accuracy: 0.8045 - val_loss: 0.4785 - val_accuracy: 0.7437\n",
            "Epoch 6/10\n",
            "67/67 [==============================] - 16s 232ms/step - loss: 0.3857 - accuracy: 0.8199 - val_loss: 0.4835 - val_accuracy: 0.7417\n",
            "Epoch 7/10\n",
            "67/67 [==============================] - 15s 230ms/step - loss: 0.3867 - accuracy: 0.8077 - val_loss: 0.4843 - val_accuracy: 0.7469\n",
            "Epoch 8/10\n",
            "67/67 [==============================] - 15s 227ms/step - loss: 0.3780 - accuracy: 0.8217 - val_loss: 0.5108 - val_accuracy: 0.7365\n",
            "Epoch 9/10\n",
            "67/67 [==============================] - 15s 227ms/step - loss: 0.3727 - accuracy: 0.8175 - val_loss: 0.4799 - val_accuracy: 0.7521\n",
            "Epoch 10/10\n",
            "67/67 [==============================] - 15s 230ms/step - loss: 0.3828 - accuracy: 0.8241 - val_loss: 0.5154 - val_accuracy: 0.7344\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x22742d99b20>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "student_model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
        "                    epochs=10,                  \n",
        "                    shuffle = True,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=test_generator.n // BATCH_SIZE,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Stephanie\\anaconda3\\envs\\ece1512\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  warnings.warn('Custom mask layers require a config and must override '\n"
          ]
        }
      ],
      "source": [
        "student_model.save(r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\models\\mhist_model_stu_init.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "mobilenet.trainable = True\n",
        "\n",
        "LEARNING_RATE = 0.0001\n",
        "student_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "67/67 [==============================] - 19s 252ms/step - loss: 0.5663 - accuracy: 0.7102 - val_loss: 0.5835 - val_accuracy: 0.6479\n",
            "Epoch 2/25\n",
            "67/67 [==============================] - 16s 241ms/step - loss: 0.4684 - accuracy: 0.7476 - val_loss: 0.5031 - val_accuracy: 0.6458\n",
            "Epoch 3/25\n",
            "67/67 [==============================] - 16s 240ms/step - loss: 0.4676 - accuracy: 0.7490 - val_loss: 0.5282 - val_accuracy: 0.6427\n",
            "Epoch 4/25\n",
            "67/67 [==============================] - 16s 244ms/step - loss: 0.4348 - accuracy: 0.7569 - val_loss: 0.5074 - val_accuracy: 0.6990\n",
            "Epoch 5/25\n",
            "67/67 [==============================] - 16s 238ms/step - loss: 0.3702 - accuracy: 0.8190 - val_loss: 0.5557 - val_accuracy: 0.7125\n",
            "Epoch 6/25\n",
            "67/67 [==============================] - 16s 237ms/step - loss: 0.3605 - accuracy: 0.8259 - val_loss: 0.4858 - val_accuracy: 0.7906\n",
            "Epoch 7/25\n",
            "67/67 [==============================] - 16s 237ms/step - loss: 0.3174 - accuracy: 0.8507 - val_loss: 0.6043 - val_accuracy: 0.7812\n",
            "Epoch 8/25\n",
            "67/67 [==============================] - 16s 238ms/step - loss: 0.3238 - accuracy: 0.8497 - val_loss: 0.5877 - val_accuracy: 0.7052\n",
            "Epoch 9/25\n",
            "67/67 [==============================] - 16s 237ms/step - loss: 0.3042 - accuracy: 0.8619 - val_loss: 0.3987 - val_accuracy: 0.8094\n",
            "Epoch 10/25\n",
            "67/67 [==============================] - 16s 237ms/step - loss: 0.2756 - accuracy: 0.8740 - val_loss: 0.3708 - val_accuracy: 0.8385\n",
            "Epoch 11/25\n",
            "67/67 [==============================] - 16s 238ms/step - loss: 0.2974 - accuracy: 0.8637 - val_loss: 0.4742 - val_accuracy: 0.8125\n",
            "Epoch 12/25\n",
            "67/67 [==============================] - 16s 241ms/step - loss: 0.2825 - accuracy: 0.8759 - val_loss: 0.4752 - val_accuracy: 0.7927\n",
            "Epoch 13/25\n",
            "67/67 [==============================] - 16s 238ms/step - loss: 0.2403 - accuracy: 0.8922 - val_loss: 0.4186 - val_accuracy: 0.8188\n",
            "Epoch 14/25\n",
            "67/67 [==============================] - 16s 236ms/step - loss: 0.2632 - accuracy: 0.8838 - val_loss: 0.4242 - val_accuracy: 0.8021\n",
            "Epoch 15/25\n",
            "67/67 [==============================] - 16s 237ms/step - loss: 0.2616 - accuracy: 0.8824 - val_loss: 0.3604 - val_accuracy: 0.8313\n",
            "Epoch 16/25\n",
            "67/67 [==============================] - 16s 239ms/step - loss: 0.2276 - accuracy: 0.9015 - val_loss: 0.4598 - val_accuracy: 0.8313\n",
            "Epoch 17/25\n",
            "67/67 [==============================] - 16s 234ms/step - loss: 0.2462 - accuracy: 0.8964 - val_loss: 0.3718 - val_accuracy: 0.8406\n",
            "Epoch 18/25\n",
            "67/67 [==============================] - 16s 235ms/step - loss: 0.2201 - accuracy: 0.9062 - val_loss: 0.4954 - val_accuracy: 0.8177\n",
            "Epoch 19/25\n",
            "67/67 [==============================] - 16s 238ms/step - loss: 0.2217 - accuracy: 0.9095 - val_loss: 0.4726 - val_accuracy: 0.8271\n",
            "Epoch 20/25\n",
            "67/67 [==============================] - 16s 241ms/step - loss: 0.1890 - accuracy: 0.9216 - val_loss: 0.3848 - val_accuracy: 0.8344\n",
            "Epoch 21/25\n",
            "67/67 [==============================] - 16s 238ms/step - loss: 0.1891 - accuracy: 0.9253 - val_loss: 0.3645 - val_accuracy: 0.8490\n",
            "Epoch 22/25\n",
            "67/67 [==============================] - 16s 237ms/step - loss: 0.1865 - accuracy: 0.9225 - val_loss: 0.6874 - val_accuracy: 0.7812\n",
            "Epoch 23/25\n",
            "67/67 [==============================] - 16s 236ms/step - loss: 0.1840 - accuracy: 0.9179 - val_loss: 0.4196 - val_accuracy: 0.8292\n",
            "Epoch 24/25\n",
            "67/67 [==============================] - 16s 241ms/step - loss: 0.1787 - accuracy: 0.9263 - val_loss: 0.3915 - val_accuracy: 0.8271\n",
            "Epoch 25/25\n",
            "67/67 [==============================] - 16s 238ms/step - loss: 0.1906 - accuracy: 0.9225 - val_loss: 0.6115 - val_accuracy: 0.8021\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x226f5dbddc0>"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "student_model.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
        "                    epochs=25,                  \n",
        "                    shuffle = True,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=test_generator.n // BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "student_model.save(r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\models\\mhist_model_stu_fine.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "student_model = keras.models.load_model(r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\models\\mhist_model_stu_fine.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Stephanie\\anaconda3\\envs\\ece1512\\lib\\site-packages\\keras\\engine\\training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1-score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0.790257</td>\n",
              "      <td>0.946515</td>\n",
              "      <td>0.861357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>0.861345</td>\n",
              "      <td>0.569444</td>\n",
              "      <td>0.685619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>accuracy</th>\n",
              "      <td>0.807574</td>\n",
              "      <td>0.807574</td>\n",
              "      <td>0.807574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>macro avg</th>\n",
              "      <td>0.825801</td>\n",
              "      <td>0.757980</td>\n",
              "      <td>0.773488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>weighted avg</th>\n",
              "      <td>0.816451</td>\n",
              "      <td>0.807574</td>\n",
              "      <td>0.796602</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              precision    recall  f1-score\n",
              "0.0            0.790257  0.946515  0.861357\n",
              "1.0            0.861345  0.569444  0.685619\n",
              "accuracy       0.807574  0.807574  0.807574\n",
              "macro avg      0.825801  0.757980  0.773488\n",
              "weighted avg   0.816451  0.807574  0.796602"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data = []\n",
        "test_labels = []\n",
        "\n",
        "for j in range(len(test_generator)):\n",
        "    test_labels += test_generator[j][1].tolist()\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "pred = student_model.predict_generator(test_generator)\n",
        "pred_classes = []\n",
        "\n",
        "\n",
        "\n",
        "for i in pred:\n",
        "    if i[0] < 0:\n",
        "        pred_classes.append(0)\n",
        "    else:\n",
        "        pred_classes.append(1)\n",
        "\n",
        "report = classification_report(test_labels,pred_classes,output_dict=True)\n",
        "df = pd.DataFrame(report).transpose()\n",
        "df.pop('support')\n",
        "df = pd.concat([df[0:8] , df[10:]])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS8xkuH0QbOS"
      },
      "source": [
        "# Student loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "lDKia4gPQMIr"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = tf.nn.sigmoid(teacher_logits)\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.sigmoid_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels):\n",
        "  \"\"\"Compute class knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_class_logits = student_model(images, training=True)\n",
        "\n",
        "  # Compute class distillation loss between student class logits and\n",
        "  # softened teacher class targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_class_logits = teacher_model(images, training=False)\n",
        "  distillation_loss_value = distillation_loss(teacher_class_logits, student_class_logits, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  loss = keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "  \n",
        "  cross_entropy_loss_value = loss(labels,student_class_logits).numpy()\n",
        "\n",
        "  return ALPHA*cross_entropy_loss_value + (1-ALPHA)*distillation_loss_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "teacher_model = keras.models.load_model(r'D:\\Github Repos\\ECE1512\\-ECE1512_2022W_ProjectRepo_StephanieDiNunzio\\Project B\\Project_B_Supp\\models\\mhist_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "test loss, test acc: [0.6105268001556396, 0.8034800291061401]\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = student_model.evaluate_generator(generator=test_generator)\n",
        "print(\"test loss, test acc:\", results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From C:\\Users\\Stephanie\\anaconda3\\envs\\ece1512\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py:5063: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "223623861408\n",
            "19604148192\n"
          ]
        }
      ],
      "source": [
        "from keras_flops import get_flops\n",
        "\n",
        "flops_teacher = get_flops(teacher_model, batch_size=BATCH_SIZE)\n",
        "print(flops_teacher)\n",
        "flops_student = get_flops(student_model, batch_size=BATCH_SIZE)\n",
        "print(flops_student)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_22 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_10  (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.5 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 2.5 #temperature hyperparameter\n",
        "\n",
        "\n",
        "# Build student.\n",
        "\n",
        "mobilenet2 = tf.keras.applications.mobilenet_v2.MobileNetV2(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
        "mobilenet2.trainable = False\n",
        "\n",
        "inputs3 = keras.Input(shape=(224,224,3))\n",
        "z = mobilenet2(inputs3, training=False)\n",
        "z= layers.GlobalAveragePooling2D()(z)\n",
        "outputs3 = layers.Dense(1)(z)\n",
        "\n",
        "student_model_KD = keras.Model(inputs3, outputs3)\n",
        "student_model_KD.summary()\n",
        "\n",
        "\n",
        "# \n",
        "\n",
        "LEARNING_RATE = 0.001\n",
        "student_model_KD.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),\n",
        "              loss=compute_student_loss,\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "student_model_KD.fit(train_generator,\n",
        "                    steps_per_epoch=train_generator.n // BATCH_SIZE,\n",
        "                    epochs=25,                  \n",
        "                    shuffle = True,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_generator,\n",
        "                    validation_steps=test_generator.n // BATCH_SIZE)# Student loss function\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Task1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
